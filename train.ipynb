{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaaa958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e0faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  os\n",
    "os.chdir('/content/drive/MyDrive/sm-embedder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e061a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from preprocessing import images_dataset_from_tfrecord\n",
    "from train import train_head, export_centers\n",
    "from evaluation import \\\n",
    "        inference, \\\n",
    "        labels_from_embeddings, \\\n",
    "        export_embeddings_for_visualization, \\\n",
    "        export_metadata, \\\n",
    "        export_projector_data, \\\n",
    "        get_results_summary \n",
    "\n",
    "build_dir = \"/home/duo/sm-embedder/build\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae82a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The hyperparameters will be defined here for cleanliness. No need to expose them. \n",
    "head_model, centers = train_head(os.path.join(build_dir, 'checkpoints/head'),\n",
    "                                 train_record=os.path.join(build_dir, 'train_featuremaps.tfrecord'),\n",
    "                                 val_record=os.path.join(build_dir, 'val_featuremaps.tfrecord'),\n",
    "                                 num_classes=20,\n",
    "                                 featuremaps_dim=1280,\n",
    "                                 embedder_dim=32,\n",
    "                                 centerloss_alpha=0.8,\n",
    "                                 logs_dir=os.path.join(build_dir, 'logs/'),\n",
    "                                 batch_size=32,\n",
    "                                 epochs=10,\n",
    "                                 steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136531cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we export the centers, we will need them later.\n",
    "export_centers(centers, os.path.join(build_dir, 'centers.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1275e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we compute the embeddings for the test.tfrecord dataset. \n",
    "test_dataset_embeddings = inference(head_checkpoint=os.path.join(build_dir, 'checkpoints/head'),\n",
    "                                    dataset_record=os.path.join(build_dir, 'test.tfrecord'),\n",
    "                                    input_shape=(300, 300, 3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bcfea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset again to get the labels\n",
    "labels_dataset = images_dataset_from_tfrecord(os.path.join(build_dir, 'test.tfrecord'))\n",
    "labels_it = labels_dataset.map(lambda x: x['label']).as_numpy_iterator()\n",
    "real_labels = np.array(list(labels_it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d50e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading centers from tsv file\n",
    "centers = np.loadtxt(os.path.join(build_dir, 'centers.tsv'))\n",
    "inferred_labels = labels_from_embeddings(test_dataset_embeddings, centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab06094",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = get_results_summary(inferred_labels, real_labels)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c71974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the centers and the computed embeddings to a single file for visuals \n",
    "# The two files you want to load on projector.tensorflow.org are:\n",
    "#     - inference_embeddings.tsv: contains the the centers and the inferred embeddings\n",
    "#     - metadata.tsv: contains the labels for each center and embeddings\n",
    "export_embeddings_for_visualization(\n",
    "        embeddings=test_dataset_embeddings,\n",
    "        filename=os.path.join(build_dir, 'inference_embeddings.tsv'),\n",
    "        centers_filename=os.path.join(build_dir,'centers.tsv'))\n",
    "\n",
    "export_metadata(os.path.join(build_dir, 'metadata.tsv'), real_labels, num_classes=20)\n",
    "\n",
    "# Also exporting embeddings data to tensorboard. I don't know why, but the labels\n",
    "# are not working... you can load them manually from \". (build_dir)/metadata.tsv\"\n",
    "embs_for_projector = np.loadtxt(os.path.join(build_dir, 'inference_embeddings.tsv'))\n",
    "export_projector_data(\n",
    "        embs_for_projector,\n",
    "        os.path.join(build_dir, 'metadata.tsv'),\n",
    "        os.path.join(build_dir, 'logs/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1e7738",
   "metadata": {},
   "source": [
    "# That's all folks! Thank you for your time an patience! \n",
    "# I hope you enjoyed!\n",
    "# Take a look at the build_dir to see all the artifacts generated.\n",
    "# Cya!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
